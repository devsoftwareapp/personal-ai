<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Personal AI</title>
<style>
body{
  background:#0f0f0f;
  color:#fff;
  font-family:system-ui;
  padding:20px;
}
#chat{
  white-space:pre-wrap;
  margin-top:20px;
}
input,button{
  padding:10px;
  font-size:16px;
}
</style>
</head>
<body>

<h2 id="status">Loading AI...</h2>

<input id="input" placeholder="Message">
<button onclick="send()">Send</button>

<div id="chat"></div>

<script type="module">

import { pipeline, env } from
"https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2";

env.allowLocalModels = false;
env.useBrowserCache = true;

let pipe;

const system =
"You are a helpful assistant.";

let history = system;

// LOAD
async function init(){

  document.getElementById("status").innerText =
  "Downloading model...";

  pipe = await pipeline(
    "text-generation",
    "Xenova/gpt2",
    {
      quantized:true
    }
  );

  document.getElementById("status").innerText =
  "AI Ready";

}

// SEND
window.send = async function(){

  if(!pipe){
    alert("Wait for AI to load");
    return;
  }

  const input =
  document.getElementById("input");

  const chat =
  document.getElementById("chat");

  const msg =
  input.value.trim();

  if(!msg)return;

  chat.innerHTML +=
  "\nYOU: "+msg+
  "\nAI: ...";

  input.value="";

  const prompt =
  history+
  "\nUser:"+msg+
  "\nAssistant:";

  const out =
  await pipe(prompt,{
    max_new_tokens:50,
    temperature:0.7
  });

  const full =
  out[0].generated_text;

  let reply =
  full.slice(prompt.length).trim();

  if(!reply) reply="Ok.";

  chat.innerHTML =
  chat.innerHTML.replace(
  "AI: ...",
  "AI: "+reply
  );

  history+=
  "\nUser:"+msg+
  "\nAssistant:"+reply;

}

init();

</script>

</body>
</html>
